{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fisheyolo_AM.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "hA_kaO4vxS8S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # import necessary files of yolo\n",
        "from google.colab import files \n",
        "util = files.upload()       # select util.py for upload\n",
        "darknet = files.upload()    # select darknet.py for upload \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qzv2icpNxyk-",
        "colab_type": "code",
        "outputId": "7e063cad-f015-46f4-f6ef-2a435b7eacf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# these two lines are to mount google drive for writing and reading directly\n",
        "from google.colab import drive      \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "K3z2sHaDbIA8",
        "colab_type": "code",
        "outputId": "740131ac-b4d1-4574-b89f-c0877dc6ce56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import sys\n",
        "import os.path\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import pickle as pkl\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "from util import *\n",
        "from darknet import Darknet\n",
        "from scipy import ndimage\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(cv.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.4.3\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ScQ1sNjgbLQe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def padding(image,psize):\n",
        "  # ****************************************************************************\n",
        "  # function to zero-padding image on its right and bottom side to a square of psize*psize. \n",
        "  # input: 1. image: image for zero-padding\n",
        "  #        2. psize: size of zero-padded image\n",
        "  # output: image padded to shape of psize*psize*3\n",
        "  # output is processed for gpu\n",
        "  # ****************************************************************************\n",
        "  \n",
        "  \n",
        "  xsize = image.shape[0]\n",
        "  ysize = image.shape[1]\n",
        "  pd_img = np.zeros((psize,psize,3),dtype = np.uint8)\n",
        "  pd_img[0:xsize,0:ysize,:] = image\n",
        "  pd_img = pd_img[:,:,::-1].transpose((2,0,1)).copy()   #reverse order of channels to RGB\n",
        "  pd_img = torch.from_numpy(pd_img).float().div(255.0).unsqueeze(0)   \n",
        "  return pd_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ARetKrL1bTEj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reverseMap(box,shape):\n",
        "  # ****************************************************************************\n",
        "  # function to reverse map detections(BBs) from each focus window to complete fisheye image\n",
        "  # only center of BB is mapped reversely\n",
        "  # input: 1. box: detection(BB) from focus window, \n",
        "  #           8-dimensional vector, [x,y,w,h,objectness, classId, confidence, anlge]\n",
        "  #        2. shape: shape of destination fisheye image\n",
        "  # output: reverse mapped to complete fisheye image\n",
        "  #         only x,y,angle will be revised in this function\n",
        "  #         x,y will be changed from coordinates in focus window to coordinates in fisheye image\n",
        "  #         angle will be changed from focus window's angle position to angle position of center of mapped BB\n",
        "  # ****************************************************************************\n",
        "  \n",
        "  \n",
        "  angle = box[7]      # the angle of focus window\n",
        "  zx = int(shape[0]/2)  # shape of fisheye image\n",
        "  zy = int(shape[1]/2)\n",
        "  ox = 624     # (left,top) of a focus window(1300*800) from top-center of a fisheye image(2048*2048)\n",
        "  oy = 0\n",
        "  # calculate new x,y for reverse-mapped BB\n",
        "  alpha = math.radians(-angle)\n",
        "  rotationMatrix = np.array([[math.cos(alpha), -math.sin(alpha)], [math.sin(alpha), math.cos(alpha)]])\n",
        "  xy = np.array([[box[0]+ox-zx],[zy-box[1]-oy]])\n",
        "  xy_ = np.matmul(rotationMatrix, xy)\n",
        "  xy_ = np.transpose(xy_)\n",
        "  xy_[0][0] = xy_[0][0] + zx\n",
        "  xy_[0][1] = zy - xy_[0][1]\n",
        "  xy_ = xy_.tolist()\n",
        "  cx = int(xy_[0][0])\n",
        "  cy = int(xy_[0][1])\n",
        "  # calculate angle for reverse-mapped BB\n",
        "  dx = cx - zx\n",
        "  dy = zy - cy\n",
        "  if dx <= 0:\n",
        "    theta = math.atan(dy/min(-0.01,dx)) - math.pi # avoid a/0\n",
        "  else:\n",
        "    theta = math.atan(dy/dx)\n",
        "  theta = math.degrees(theta)\n",
        "  box[0] = cx\n",
        "  box[1] = cy\n",
        "  box[7] = theta\n",
        "  return box"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IToc1lPZbVFX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def topoints(shape,box):\n",
        "  # ****************************************************************************\n",
        "  # Get the coordinates of four vertices of BBs in fisheye image\n",
        "  # input: 1. shape: shape of fisheye image\n",
        "  #        2. box: BBs to interpret \n",
        "  # output: list of cooperates of four vertices of the BB\n",
        "  # ****************************************************************************\n",
        "  \n",
        "  \n",
        "  # set center of image as origin.\n",
        "  ox = int(shape[0]/2)\n",
        "  oy = int(shape[0]/2)\n",
        "  # get coordinate of center of BB in the new coordinate system\n",
        "  cx = box[0] - ox\n",
        "  cy = oy - box[1]\n",
        "  # calculate four vertices based on a series of tiangular calculations\n",
        "  theta = math.radians(box[7])\n",
        "  wc = box[2]*math.cos(theta)/2\n",
        "  hc = box[3]*math.cos(theta)/2\n",
        "  ws = box[2]*math.sin(theta)/2\n",
        "  hs = box[3]*math.sin(theta)/2\n",
        "  sign = [[-1,1,1,1,],[1,1,-1,1],[1,-1,-1,-1],[-1,-1,1,-1]]\n",
        "  # output\n",
        "  pts = []\n",
        "  for i in sign:\n",
        "    pts.append((int(cx+i[0]*ws+i[1]*hc)+ox,oy-int(cy+i[2]*wc+i[3]*hs)))\n",
        "  return(pts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CchsmGvwbXq1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def drawBB(image,boxes,color):\n",
        "  # ****************************************************************************\n",
        "  # function to draw BBs \n",
        "  # input: 1. image: image to draw BBs on\n",
        "  #        2. boxes: Bounding boxes to draw\n",
        "  #        3. color: color for BB\n",
        "  # ****************************************************************************\n",
        "  \n",
        "  \n",
        "  for box in boxes:\n",
        "    pts = topoints(image.shape,box) # get the vertices of BB\n",
        "    for i in range(0,5):\n",
        "      cv.line(image,pts[i%4],pts[(i-1)%4],color,3) # link vertices in order"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6r9Wqu1AdZtB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def randomize(image,num):\n",
        "  # ****************************************************************************\n",
        "  # function to add randomisty to small image candidate for verification\n",
        "  # input: 1. image: small image\n",
        "  #        2. num: number of small image, used to select random seed for gaussian noise\n",
        "  # output: horizontally flipped small image with noise\n",
        "  \n",
        "  # *********************NOT USED IN THESIS*************************************\n",
        "  # ****************************************************************************\n",
        "  \n",
        "  \n",
        "  image = cv.flip(image, 1) # flip horizontally\n",
        "  np.random.seed(num)  # select a random seed\n",
        "  noise = np.random.normal(20,10,image.shape) # generate 2D gaussian noise\n",
        "  noise[noise<0]=0 # truncate the noise into range of o to 255\n",
        "  noise[noise>255] = 255\n",
        "  for i in range(0,3):\n",
        "    image[:,:,i] = image[:,:,i] #+ noise[:,:,i]    #add the noise to image\n",
        "    cv.imwrite(savepath+str(num)+\"_\"+str(i)+\".jpg\",image)\n",
        "  return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PPK5i6rCbZld",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def NMS(boxes, shape ,th):\n",
        "  # ****************************************************************************\n",
        "  # function to merge reverse-mapped boxes using NMS-based method\n",
        "  # detail can be found in 3.6.1 of Shengye's thesis\n",
        "  # pseudo code avaibliable in Algorithm 1 of my thesis\n",
        "  # input: 1. boxes: all BBs after reverse mapping\n",
        "  #        2. shape: shape of fisheye image\n",
        "  #        3. th: threshold for IOU. if IOU > th, two BBs will be merged.\n",
        "  # output: a group of BBs of which any pair's IOU < th\n",
        "  # ****************************************************************************\n",
        "  \n",
        "  \n",
        "  xsize = shape[0]\n",
        "  ysize = shape[1]\n",
        "  confidences = [] #list to store confidence score \n",
        "  result = [] # list of output, initialized here\n",
        "  # extract the confidence score from input BBs, and sort it in descending order.\n",
        "  for box in boxes:\n",
        "    confidences.append(box[6])\n",
        "  idxs = sorted(range(len(confidences)), key=lambda k: confidences[k],reverse=True)\n",
        "  # NMS \n",
        "  for ii in range(len(idxs)):\n",
        "    # if output list is empty, append the BB with highest conf. directly\n",
        "    if ii == 0:\n",
        "      result.append(boxes[idxs[ii]]) \n",
        "    else:\n",
        "      \n",
        "      i = idxs[ii]\n",
        "      # get the area of rotated rectangle by count pixels\n",
        "      # In the later version of opencv, NMS for rotated rectangles is available,\n",
        "      # Strongly suggest to change to that function provided by opencv which calculate IOU anatically.\n",
        "      refi = np.zeros((xsize,ysize))\n",
        "      pts = topoints((xsize,ysize),boxes[i])\n",
        "      contours = np.array([pts[0],pts[1],pts[2],pts[3]])\n",
        "      cv.fillPoly(refi, pts =[contours], color=(1,1,1)) \n",
        "      si = boxes[i][2]*boxes[i][3]\n",
        "      addable = 1 # flag: if it is able to add the BB into output list\n",
        "      for j in range(len(result)):\n",
        "        refj = np.zeros((xsize,ysize))\n",
        "        pts = topoints((xsize,ysize),result[j])\n",
        "        contours = np.array([pts[0],pts[1],pts[2],pts[3]])\n",
        "        cv.fillPoly(refj, pts =[contours], color=(1,1,1))\n",
        "        sj = si = result[j][2]*result[j][3]\n",
        "        ref = refj + refi\n",
        "        so = len(np.argwhere(ref == 2))\n",
        "        iou = so / (sj + si - so) # calculate IOU\n",
        "        # if IOU of this BBs and any of outputs(whose confidence socre is higher) > TH, \n",
        "        # suppress the BB.\n",
        "        if iou > th: \n",
        "          addable = 0\n",
        "          break\n",
        "      if addable == 1:\n",
        "        # otherwise append BB to the final output.\n",
        "        result.append(boxes[i])\n",
        "  return result\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CqX5ZT9YbcQj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def KMEANS(im, bbs):\n",
        "  # ****************************************************************************\n",
        "  # function to merge all BBs after reverse mapping using clustering-based method\n",
        "  # detail can be found in 3.6.2 of shengye's thesis\n",
        "  # input: 1. im: fisheye images\n",
        "  #        2. bbs: BBs after reverse mapping\n",
        "  # output: a list of BBs after merging. \n",
        "  # ****************************************************************************\n",
        "  \n",
        "  # compose feature vectors\n",
        "  bbs = np.asarray(bbs)\n",
        "  features = np.zeros((bbs.shape[0],12)) # compose a 12-dimensional feature vector\n",
        "  features[:,0] = bbs[:,0]/2048 # normalize x\n",
        "  features[:,1] = bbs[:,1]/2048 # normalize y\n",
        "  T = bbs[:,7]\n",
        "  X = bbs[:,0]\n",
        "  Y = bbs[:,1]\n",
        "  W = bbs[:,2]\n",
        "  H = bbs[:,3]\n",
        "  # start compose the grayscale histogram for feature vector\n",
        "  for i, delta in enumerate(T):\n",
        "    # first rotate the BB to upright position\n",
        "    M = cv.getRotationMatrix2D((cf.shape[0]/2,cf.shape[1]/2),90-delta,1)\n",
        "    image = cv.warpAffine(cf,M,(cf.shape[0],cf.shape[1]))\n",
        "    dx = X[i] - 1024\n",
        "    dy = 1024 - Y[i]\n",
        "    alpha = math.radians(90-delta)\n",
        "    rotationMatrix = np.array([[math.cos(alpha), -math.sin(alpha)], [math.sin(alpha), math.cos(alpha)]])\n",
        "    xy = np.array([[dx],[dy]])\n",
        "    xy_ = np.matmul(rotationMatrix, xy)\n",
        "    xy_ = np.transpose(xy_)\n",
        "    xy_ = xy_.tolist()\n",
        "    cx = int(xy_[0][0]) + 1024\n",
        "    cy = 1024 - int(xy_[0][1])\n",
        "    margin = 0 # get area exactly same as BB\n",
        "    # calculate the four vertices of rectangular area to extract grayscale histogram\n",
        "    top = max(cy - margin - int(H[i] / 2),0)\n",
        "    left = max(cx - margin - int(W[i] / 2),0)\n",
        "    right = min(cx + margin + int(W[i] / 2),2048)\n",
        "    bottom = min(cy + margin + int(H[i] / 2),2048)  \n",
        "    roi = image[top:bottom,left:right,:] # extract area inside of BB from fisheye image\n",
        "    roi = cv.cvtColor(roi, cv.COLOR_BGR2GRAY) # convert to grayscale\n",
        "    roi.reshape(1,roi.shape[0]*roi.shape[1]) # reshape to 1*n vector\n",
        "    hist = np.histogram(roi,bins=10,range=(0,260),density=False) # 10-bin historgram\n",
        "    features[i,2:12] = 0.8 * hist[0] / (roi.shape[0]*roi.shape[1])\n",
        "  inertia = np.zeros((features.shape[0]))\n",
        "  costf = np.zeros((features.shape[0]))\n",
        "  y = range(1,features.shape[0]+1)\n",
        "  for i in range(1, features.shape[0]+1): \n",
        "    kmeans = KMeans(n_clusters = i, random_state=0) # do kmeans with fixed random seed\n",
        "    kmeans.fit(features) # input features\n",
        "    inertia[i-1] = kmeans.inertia_  # cost function without regularization\n",
        "    costf[i-1] = kmeans.inertia_ + 0.0025*i**2 # cost function with regularization\n",
        "# # plot and save the cost function if needed\n",
        "#   plt.plot(inertia)\n",
        "#   plt.savefig(savepath + \"Kmeans_\" + str(numberofframe) + \".jpg\")\n",
        "#   plt.clf()\n",
        "#   plt.plot(costf)\n",
        "#   plt.savefig(savepath + \"Cost_\" + str(numberofframe) + \".jpg\")\n",
        "#   plt.clf()\n",
        "#   numofcluster = elbow(costf)\n",
        "#   print(costf)\n",
        "#   print(inertia)\n",
        "  numofcluster = np.argmin(costf) + 1 # find the K with minimum cost\n",
        "  kmeans = KMeans(n_clusters = numofcluster, random_state=0) # do Kmeans again to cluster\n",
        "  kmeans.fit(features)\n",
        "  result = []\n",
        "  # generate a representeive BB for each cluster(person)\n",
        "  for i in range(0,numofcluster):\n",
        "    cx = int(np.mean(features[kmeans.labels_ == i,0])*2048)\n",
        "    cy = int(np.mean(features[kmeans.labels_ == i,1])*2048)\n",
        "    width = int(np.mean(bbs[kmeans.labels_ == i,2]))\n",
        "    height = int(np.mean(bbs[kmeans.labels_ == i,3]))\n",
        "    dx = cx - 1024\n",
        "    dy = 1024 - cy\n",
        "    if dx <= 0:\n",
        "      theta = math.atan(dy/min(-0.01,dx)) - math.pi\n",
        "    else:\n",
        "      theta = math.atan(dy/dx)\n",
        "    result.append([cx,cy,width,height,0,0,0,math.degrees(theta)])\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_WrrXB6ZdS4V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def check(image):\n",
        "  # ****************************************************************************  \n",
        "  # function for connected components analysis and to remove small-area components\n",
        "  # input: 1. image: binary image after morphological filtering\n",
        "  # output: a list of numbers that are labels of large-area components\n",
        "  # ****************************************************************************\n",
        "  \n",
        "  \n",
        "  validarea = []\n",
        "  _, d = cv.connectedComponents(image)\n",
        "  for i in range(1,np.amax(d)+1):\n",
        "    location = np.argwhere(d == i)\n",
        "    if len(location) > 3600: # remove area smaller than 3600 pixels\n",
        "      validarea.append(i) \n",
        "  return validarea "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e22lkyYVA574",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def thetacheck(theta):\n",
        "  # ****************************************************************************\n",
        "  # function to ensure theta of focus window is in range from 0 to 360\n",
        "  # input: theta\n",
        "  # output: checked theta in range of (3,360)\n",
        "  # ****************************************************************************\n",
        "  \n",
        "  if theta < 0:\n",
        "    theta = theta + 360\n",
        "  elif theta >= 360:\n",
        "    theta = theta - 360\n",
        "  return theta"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DoIA6hbRbeUH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set the path for model, weights, coco.names files\n",
        "path = \"/content/gdrive/My Drive/Colab Notebooks/\"\n",
        "clasess = load_classes(path + \"coco.names\")\n",
        "model = Darknet(path + \"yolov3.cfg\")\n",
        "model.load_weights(path + \"yolov3.weights\")\n",
        "CUDA = torch.cuda.is_available()   # if gpu is avaliable\n",
        "readpath = \"/content/gdrive/My Drive/frames_of_test118c/\"     #path to read images\n",
        "savepath = \"/content/gdrive/My Drive/AM_NMS_no_margin_442b1/\"     #path to write results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0WNFUGnOewCX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initialization of background model\n",
        "bg = np.zeros((2048,2048,3),dtype = np.uint8)\n",
        "\n",
        "# list to count time\n",
        "time_ROI = []\n",
        "time_detection = []\n",
        "time_counting = []\n",
        "time_verification = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xnKvavy4bgZ2",
        "colab_type": "code",
        "outputId": "1f5bc285-5890-4bd2-94c2-b087af4c4e61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        }
      },
      "cell_type": "code",
      "source": [
        "for numberofframe in range(71,1172,20):\n",
        "  cf = cv.imread(readpath + str(numberofframe) + \".jpg\")\n",
        "  begin = time.time()\n",
        "  loaded_ims = []\n",
        "  psize = 0\n",
        "  # ROI extraction--------------------------------------------------------------\n",
        "  #background subtraction\n",
        "  if numberofframe == 1: # the first detection is same as activity-blind method \n",
        "    angles = range(0,360,15)\n",
        "  else:\n",
        "    th = 30 # threshold for significant difference between background and current frame\n",
        "    diff = cv.absdiff(bg, cf) # absolute differnece of R,G,B channels\n",
        "    _,diff_r = cv.threshold(diff[:,:,0], th, 1, cv.THRESH_BINARY)\n",
        "    _,diff_g = cv.threshold(diff[:,:,1], th, 1, cv.THRESH_BINARY)\n",
        "    _,diff_b = cv.threshold(diff[:,:,2], th, 1, cv.THRESH_BINARY)\n",
        "    diff = diff_b + diff_r + diff_g # sum the diffenrence in three channels up together\n",
        "    _, diff = cv.threshold(diff, 1, 1, cv.THRESH_TRUNC) # convert to binary result\n",
        "    \n",
        "    #morphology operations\n",
        "    kernel = cv.getStructuringElement(cv.MORPH_RECT,(3,3))\n",
        "    diff = cv.morphologyEx(diff,cv.MORPH_OPEN, kernel)\n",
        "    kernel = cv.getStructuringElement(cv.MORPH_ELLIPSE,(25,25))\n",
        "    for i in range(0,1):\n",
        "      diff = cv.dilate(diff, kernel)\n",
        "      \n",
        "    # connectivity check\n",
        "    validarea = check(diff)\n",
        "    _, diff = cv.connectedComponents(diff)\n",
        "#     # color different connected components in different colors for visualization    \n",
        "#     reference = np.zeros((bg.shape[0],bg.shape[1],3))\n",
        "#     for i in range(0, len(validarea)):\n",
        "#       reference[diff == validarea[i]]  = colors[i%(len(colors))]\n",
        "      \n",
        "    # output rois\n",
        "    angles = [] #result of selected windows\n",
        "    for i in range(0, len(validarea)):\n",
        "      reference = np.zeros((bg.shape[0],bg.shape[1]))\n",
        "      # calculate the centroid of each connected component \n",
        "      reference[diff == validarea[i]] = 1\n",
        "      m = cv.moments(reference)\n",
        "      cx = int(m[\"m10\"] / m[\"m00\"]) \n",
        "      cy = int(m[\"m01\"] / m[\"m00\"])\n",
        "      cx = cx - 1024\n",
        "      cy = 1024 - cy\n",
        "      if cy > 0:\n",
        "        theta = math.atan(cx / cy)\n",
        "      else:\n",
        "        theta = math.atan(cx / min(-0.01,cy)) - math.pi\n",
        "      # select the window closest to the centroid of components\n",
        "      theta = math.degrees(theta)\n",
        "      theta = thetacheck(theta)\n",
        "      theta = round(theta/15)*15\n",
        "      M = cv.getRotationMatrix2D((bg.shape[0]/2,bg.shape[1]/2),theta,1)\n",
        "      rotation = cv.warpAffine(reference,M,(bg.shape[0],bg.shape[1]))\n",
        "\n",
        "      roi = rotation[0:1250,624:1424]\n",
        "#       cv.imwrite(\"/Users/tom/Desktop/rotateee_\"+str(validarea[i])+\".jpg\",roi*255)\n",
        "      l1 = len(np.argwhere(roi[:,0:200] == 1)) \n",
        "      l2 = len(np.argwhere(roi[:,roi.shape[1]-200:roi.shape[1]] == 1))\n",
        "#       print(l1)\n",
        "#       print(l2)\n",
        "#       print(thetacheck(theta))\n",
        "\n",
        "      if l1==0 and l2==0: # component is fully contained by a focus window\n",
        "        angles.append(thetacheck(theta))\n",
        "      else: # if not fully contained, add the neighboring one too\n",
        "        angles.append(thetacheck(theta))\n",
        "        if l1 > 0:\n",
        "#           print(\"left:\")\n",
        "          for j in range(15,180,15):\n",
        "            alpha = theta - j\n",
        "            M = cv.getRotationMatrix2D((bg.shape[0]/2,bg.shape[1]/2),alpha,1)\n",
        "            rotation = cv.warpAffine(reference,M,(bg.shape[0],bg.shape[1]))\n",
        "            leftroi = rotation[0:1250,624:824]\n",
        "#             cv.imwrite(\"/Users/tom/Desktop/\"+str(theta)+\"_left_\"+str(alpha)+\".jpg\",leftroi*255)\n",
        "            angles.append(thetacheck(alpha))\n",
        "#             print(len(np.argwhere(leftroi == 1)))\n",
        "            if len(np.argwhere(leftroi == 1)) == 0:\n",
        "              break\n",
        "        if l2 > 0:\n",
        "#           print(\"right:\")\n",
        "          for j in range(15,180,15):\n",
        "            alpha = theta + j\n",
        "            M = cv.getRotationMatrix2D((bg.shape[0]/2,bg.shape[1]/2),alpha,1)\n",
        "            rotation = cv.warpAffine(reference,M,(bg.shape[0],bg.shape[1]))\n",
        "            rightroi = rotation[0:1250,1224:1424]\n",
        "#             cv.imwrite(\"/Users/tom/Desktop/\"+str(theta)+\"_right_\"+str(alpha)+\".jpg\",rightroi*255)\n",
        "            angles.append(thetacheck(alpha))\n",
        "#             print(len(np.argwhere(rightroi == 1)))\n",
        "            if len(np.argwhere(rightroi == 1)) == 0 :\n",
        "              break\n",
        "#       print(\"````\")\n",
        "\n",
        "    angles = sorted(list(set(angles)))\n",
        "#     print(angles)\n",
        "          \n",
        "  # get roi---------------------------------------------------------------------\n",
        "  # Extract focus window based on the result of ROI extraction\n",
        "  for angle in angles:\n",
        "    M = cv.getRotationMatrix2D((cf.shape[0]/2,cf.shape[1]/2),angle,1)\n",
        "    rotation = cv.warpAffine(cf,M,(cf.shape[0],cf.shape[1]))\n",
        "    roi = rotation[0:1300,624:1424,:]\n",
        "    loaded_ims.append(roi)\n",
        "    psize = max(roi.shape[0],roi.shape[1],psize)\n",
        "  stop0 = time.time()\n",
        "  time_ROI.append(stop0 - begin)\n",
        "  \n",
        "  # prepart batch---------------------------------------------------------------\n",
        "  batch_size = 2 # divide images into bathes, and feed into YOLO\n",
        "  psize = int(np.ceil(psize/32)*32)  # image feed into YOLO must have a shape of n*32\n",
        "  model.net_info[\"height\"] = int(psize) # set input size for darknet \n",
        "  model.cuda()\n",
        "  im_batches = list(map(padding, loaded_ims, [psize for x in range(len(loaded_ims))]))\n",
        "  im_dim_list = [(x.shape[1], x.shape[0]) for x in loaded_ims]\n",
        "  im_dim_list = torch.FloatTensor(im_dim_list).repeat(1,2)\n",
        "  leftover = 0\n",
        "  if (len(im_dim_list) % batch_size):\n",
        "    leftover = 1\n",
        "  if batch_size != 1:\n",
        "    num_batches = len(loaded_ims) // batch_size + leftover            \n",
        "    im_batches = [torch.cat((im_batches[i*batch_size : min((i +  1)*batch_size, \n",
        "                                                           len(im_batches))]))  for i in range(num_batches)]   # zero-padding images\n",
        "  im_dim_list = im_dim_list.cuda()\n",
        "  \n",
        "  # detection-------------------------------------------------------------------\n",
        "  persons = []\n",
        "  for i, batch in enumerate(im_batches):\n",
        "    batch = batch.cuda()\n",
        "    with torch.no_grad():\n",
        "      prediction = model(Variable(batch), CUDA)\n",
        "    prediction = write_results(prediction, 0.3, 80, nms_conf = 0.4)\n",
        "    if type(prediction) != int:\n",
        "      for pred in prediction:\n",
        "        detection = pred.cpu().numpy()\n",
        "        ind = int(pred[0])\n",
        "        factor = 1312 / psize\n",
        "        cx = int(factor * (detection[1] + detection[3])/2)\n",
        "        cy = int(factor * (detection[2] + detection[4])/2)\n",
        "        width = int(factor * (detection[3] - detection[1]))\n",
        "        height = int(factor * (detection[4] - detection[2]))\n",
        "        objectness = detection[5]\n",
        "        confidence = detection[6]\n",
        "        classId = int(detection[7])\n",
        "        top = cy - height / 2\n",
        "        left = cx - width / 2\n",
        "        right = cx + width / 2\n",
        "        bottom = cy + height / 2\n",
        "        box = [cx, cy, width, height, objectness, classId, confidence, angles[i*batch_size+ind]]\n",
        "        #      0    1    2       3         4         5         6               7\n",
        "        if classId == 0: # only people detection is accepted\n",
        "          if left > 50 and right < 750 and bottom < 1250: # spatial outlier rejection\n",
        "          persons.append(box)\n",
        "  \n",
        "  # Reverse Map-----------------------------------------------------------------\n",
        "  im = cf.copy()\n",
        "  BBs = list(map(reverseMap, persons, [(2048,2048) for x in persons]))# reverse map\n",
        "  drawBB(im, BBs, (255,0, 0))# draw result of reverse map in blue\n",
        "  stop = time.time()\n",
        "  time_detection.append(stop-begin)\n",
        "  \n",
        "  # People counting ------------------------------------------------------------\n",
        "  BBs = NMS(BBs, (2048, 2048), 0.4) # choose between NMS and KMEANS\n",
        "#   BBs = KMEANS(cf, BBs)\n",
        "  drawBB(im, BBs, (0, 255,0))\n",
        "#   drawBB(im, BBs, (0,0,255))\n",
        "  stop1 = time.time()\n",
        "#   print(stop1-stop)\n",
        "  time_counting.append(stop1-stop)\n",
        "  \n",
        "#  # varification-----------------------------------------------------------------\n",
        "  verified_result = []    # list to store verified result\n",
        "  for numberofbox, box in enumerate(BBs):\n",
        "    # prepare batch\n",
        "    positive = 0  # number of \"Yes\" vote\n",
        "    psize = 0   # size for zero-padding\n",
        "    loaded_ims = [] \n",
        "    candidates = []\n",
        "    M = cv.getRotationMatrix2D((cf.shape[0]/2,cf.shape[1]/2),90-box[7],1)\n",
        "    image = cv.warpAffine(cf,M,(cf.shape[0],cf.shape[1]))\n",
        "    dx = box[0] - 1024\n",
        "    dy = 1024 - box[1]\n",
        "    alpha = math.radians(90-box[7])\n",
        "    rotationMatrix = np.array([[math.cos(alpha), -math.sin(alpha)], [math.sin(alpha), math.cos(alpha)]])\n",
        "    xy = np.array([[dx],[dy]])\n",
        "    xy_ = np.matmul(rotationMatrix, xy)\n",
        "    xy_ = np.transpose(xy_)\n",
        "    xy_ = xy_.tolist()\n",
        "    cx = int(xy_[0][0]) + 1024\n",
        "    cy = 1024 - int(xy_[0][1])\n",
        "    pts = topoints((2048,2048),[cx,cy,box[2],box[3],0,0,0,90-box[7]])  \n",
        "    # extract margin slightly larger than BB\n",
        "    margin = 30\n",
        "    top = max(cy - margin - int(box[3] / 2),0)\n",
        "    left = max(cx - margin - int(box[2] / 2),0)\n",
        "    right = min(cx + margin + int(box[2] / 2),2048)\n",
        "    bottom = min(cy + margin + int(box[3] / 2),2048)    \n",
        "    roi_0 = image[top:bottom,left:right,:]   # extract the upright image \n",
        "    roi_n10 = ndimage.rotate(roi_0, -15)   # further rotate -15 degrees\n",
        "    roi_p10 = ndimage.rotate(roi_0, 15)  # future rotate 15 degrees\n",
        "    \n",
        "    loaded_ims.append(randomize(roi_n10,0))\n",
        "    loaded_ims.append(randomize(roi_0,1))\n",
        "    loaded_ims.append(randomize(roi_p10,2))\n",
        "                                 \n",
        "    for mmm, roi in enumerate(loaded_ims):\n",
        "      psize = max(roi.shape[0],roi.shape[1],psize)\n",
        "#       cv.imwrite(savepath + \"verification_\"+str(numberofbox)+\"_\"+str(mmm)+\".jpg\", roi)\n",
        "    batch_size = 3\n",
        "    psize = int(np.ceil(psize/32)*32)  # repeat steps in detection part\n",
        "    model.net_info[\"height\"] = int(psize)\n",
        "    model.cuda()\n",
        "    im_batches = list(map(padding, loaded_ims, [psize for x in range(len(loaded_ims))]))\n",
        "    im_dim_list = [(x.shape[1], x.shape[0]) for x in loaded_ims]\n",
        "    im_dim_list = torch.FloatTensor(im_dim_list).repeat(1,2)\n",
        "    leftover = 0\n",
        "    if (len(im_dim_list) % batch_size):\n",
        "      leftover = 1\n",
        "    if batch_size != 1:\n",
        "      num_batches = len(loaded_ims) // batch_size + leftover            \n",
        "      im_batches = [torch.cat((im_batches[i*batch_size : min((i + 1)*batch_size, \n",
        "                                                             len(im_batches))]))  for i in range(num_batches)]  \n",
        "    im_dim_list = im_dim_list.cuda()\n",
        "    \n",
        "    # detection\n",
        "    for i, batch in enumerate(im_batches):\n",
        "      batch = batch.cuda()\n",
        "      with torch.no_grad():\n",
        "        prediction = model(Variable(batch), CUDA)\n",
        "      prediction = write_results(prediction, 0.3, 80, nms_conf = 0) # set TH of IOU for NMS as 0\n",
        "      if type(prediction) != int:\n",
        "        for pred in prediction:\n",
        "          detection = pred.cpu().numpy()\n",
        "          ind = int(pred[0])\n",
        "          factor = 1\n",
        "          cx = int(factor * (detection[1] + detection[3])/2)\n",
        "          cy = int(factor * (detection[2] + detection[4])/2)\n",
        "          width = int(factor * (detection[3] - detection[1]))\n",
        "          height = int(factor * (detection[4] - detection[2]))\n",
        "          objectness = detection[5]\n",
        "          confidence = detection[6]\n",
        "          classId = int(detection[7])\n",
        "          veri = [cx, cy, width, height, objectness, classId, confidence, (i*batch_size+ind)*15-15]\n",
        "          #      0    1    2       3         4         5         6               7\n",
        "          if classId == 0 :#and veri[4]>0.5 and veri[6]>0.3:\n",
        "            candidates.append(veri)\n",
        "#             print(\"numberofbox: \", str(numberofbox))\n",
        "#             print(veri)\n",
        "    # vote     \n",
        "    if len(candidates) >= 2:\n",
        "      verified_result.append(box)\n",
        "      \n",
        "#   verified_result = BBs  \n",
        "  #background update------------------------------------------------------------\n",
        "  ref = np.zeros((2048,2048),dtype=np.uint8)\n",
        "  for box in verified_result:\n",
        "    pts = topoints((2048,2048),box)\n",
        "    contours = np.array([pts[0],pts[1],pts[2],pts[3]])\n",
        "    cv.fillPoly(ref, pts =[contours], color=(255,255,255))\n",
        "  alpha = 1\n",
        "  ref = ref / 255\n",
        "  for j in range(0,3):\n",
        "    bg[:,:,j] = np.multiply(ref,bg[:,:,j]) + np.multiply(1-ref, alpha * cf[:,:,j] + (1-alpha) * bg[:,:,j])\n",
        "  \n",
        "  \n",
        "  \n",
        "  #output number and location---------------------------------------------------\n",
        "  stop2 = time.time()\n",
        "  print(numberofframe,end=\": \")\n",
        "  print(stop-begin)\n",
        "  drawBB(im, verified_result, (0,0,255))  # draw verified detections in red\n",
        "  cv.imwrite(savepath + \"result_\" + str(numberofframe) + \".jpg\", im)\n",
        "  time_verification.append(stop2-stop1)\n",
        "  cv.imwrite(savepath + \"background_\" + str(numberofframe) + \".jpg\", bg)\n",
        "  torch.cuda.empty_cache()\n",
        "  \n",
        "  \n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71: 15.322063446044922\n",
            "91: 2.7071890830993652\n",
            "111: 2.7350339889526367\n",
            "131: 2.708847999572754\n",
            "151: 2.7336742877960205\n",
            "171: 2.1859915256500244\n",
            "191: 2.1645398139953613\n",
            "211: 2.2424380779266357\n",
            "231: 2.190171003341675\n",
            "251: 1.5093536376953125\n",
            "271: 2.288600444793701\n",
            "291: 1.5417711734771729\n",
            "311: 2.831912040710449\n",
            "331: 2.2067370414733887\n",
            "351: 3.496614456176758\n",
            "371: 2.181443214416504\n",
            "391: 2.187427043914795\n",
            "411: 2.9006147384643555\n",
            "431: 2.288522720336914\n",
            "451: 2.8108975887298584\n",
            "471: 3.583253860473633\n",
            "491: 3.630892753601074\n",
            "511: 2.9516496658325195\n",
            "531: 3.8229713439941406\n",
            "551: 2.8790228366851807\n",
            "571: 3.0450472831726074\n",
            "591: 5.148015022277832\n",
            "611: 3.8940024375915527\n",
            "631: 3.0947515964508057\n",
            "651: 3.012115001678467\n",
            "671: 1.577683687210083\n",
            "691: 1.5355114936828613\n",
            "711: 1.4834704399108887\n",
            "731: 1.458226203918457\n",
            "751: 2.2164857387542725\n",
            "771: 2.9463045597076416\n",
            "791: 2.3189427852630615\n",
            "811: 3.014153003692627\n",
            "831: 3.765336036682129\n",
            "851: 3.6291778087615967\n",
            "871: 2.3440444469451904\n",
            "891: 2.4410746097564697\n",
            "911: 2.314201831817627\n",
            "931: 3.6511142253875732\n",
            "951: 1.6420879364013672\n",
            "971: 1.61077880859375\n",
            "991: 1.505852460861206\n",
            "1011: 0.8821969032287598\n",
            "1031: 0.847853422164917\n",
            "1051: 0.8365342617034912\n",
            "1071: 0.8829057216644287\n",
            "1091: 2.21659779548645\n",
            "1111: 2.3431150913238525\n",
            "1131: 2.984755754470825\n",
            "1151: 3.6747913360595703\n",
            "1171: 5.125248908996582\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pG7HMJ_om7yW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(savepath+\"time_detection.csv\", mode='w') as box_file:\n",
        "  box_writer = csv.writer(box_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "  for i in time_detection:\n",
        "    box_writer.writerow([i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q9kXQcV6eCoe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(savepath+\"time_counting.csv\", mode='w') as box_file:\n",
        "  box_writer = csv.writer(box_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "  for i in time_counting:\n",
        "    box_writer.writerow([i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WpmwrbFZeGQ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(savepath+\"time_verification.csv\", mode='w') as box_file:\n",
        "  box_writer = csv.writer(box_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "  for i in time_verification:\n",
        "    box_writer.writerow([i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2y2-GPB5fbbN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(savepath+\"time_ROI.csv\", mode='w') as box_file:\n",
        "  box_writer = csv.writer(box_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "  for i in time_ROI:\n",
        "    box_writer.writerow([i])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}