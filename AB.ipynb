{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fisheyolo_BF.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "j044u0j_7uQa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import necessary files of yolo\n",
        "from google.colab import files \n",
        "util = files.upload()       # select util.py for upload\n",
        "darknet = files.upload()    # select darknet.py for upload \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1TAk_WQe8nPI",
        "colab_type": "code",
        "outputId": "5120788f-8cfe-414a-df26-f83f72a6837f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# these two lines are to mount google drive for writing and reading directly\n",
        "from google.colab import drive      \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "It17H3OE7h-k",
        "colab_type": "code",
        "outputId": "0e9262d3-f0d9-4ad0-c306-7cf559f53094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import sys\n",
        "import os.path\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import pickle as pkl\n",
        "import pandas as pd\n",
        "import random\n",
        "import time\n",
        "from util import *\n",
        "from darknet import Darknet\n",
        "from scipy import ndimage\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(cv.__version__)\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.4.3\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L6J_z7XBtMFf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set the path for model, weights, coco.names files\n",
        "path = \"/content/gdrive/My Drive/Colab Notebooks/\"\n",
        "clasess = load_classes(path + \"coco.names\")\n",
        "model = Darknet(path + \"yolov3.cfg\")\n",
        "model.load_weights(path + \"yolov3.weights\")\n",
        "CUDA = torch.cuda.is_available()    # if gpu is avaliable\n",
        "readpath = \"/content/gdrive/My Drive/framesfor4/\"    #path to read images\n",
        "savepath = \"/content/gdrive/My Drive/BF_KMEANS_446_421/\"    #path to write results\n",
        "numberofframe = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rfHpO_z-7CAE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def padding(image,psize):\n",
        "  # ****************************************************************************\n",
        "  # function to zero-padding image on its right and bottom side to a square of psize*psize. \n",
        "  # input: 1. image: image for zero-padding\n",
        "  #        2. psize: size of zero-padded image\n",
        "  # output: image padded to shape of psize*psize*3\n",
        "  # output is processed for gpu\n",
        "  # ****************************************************************************\n",
        "  \n",
        "  \n",
        "  xsize = image.shape[0]\n",
        "  ysize = image.shape[1]\n",
        "  pd_img = np.zeros((psize,psize,3),dtype = np.uint8)\n",
        "  pd_img[0:xsize,0:ysize,:] = image\n",
        "  pd_img = pd_img[:,:,::-1].transpose((2,0,1)).copy()   #reverse order of channels to RGB\n",
        "  pd_img = torch.from_numpy(pd_img).float().div(255.0).unsqueeze(0)   \n",
        "  return pd_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4CrYgB4X7Nnj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def reverseMap(box,shape):\n",
        "  # ****************************************************************************\n",
        "  # function to reverse map detections(BBs) from each focus window to complete fisheye image\n",
        "  # only center of BB is mapped reversely\n",
        "  # input: 1. box: detection(BB) from focus window, \n",
        "  #           8-dimensional vector, [x,y,w,h,objectness, classId, confidence, anlge]\n",
        "  #        2. shape: shape of destination fisheye image\n",
        "  # output: reverse mapped to complete fisheye image\n",
        "  #         only x,y,angle will be revised in this function\n",
        "  #         x,y will be changed from coordinates in focus window to coordinates in fisheye image\n",
        "  #         angle will be changed from focus window's angle position to angle position of center of mapped BB\n",
        "  # ****************************************************************************\n",
        "  \n",
        "  \n",
        "  angle = box[7]      # the angle of focus window\n",
        "  zx = int(shape[0]/2)  # shape of fisheye image\n",
        "  zy = int(shape[1]/2)\n",
        "  ox = 624     # (left,top) of a focus window(1300*800) from top-center of a fisheye image(2048*2048)\n",
        "  oy = 0\n",
        "  # calculate new x,y for reverse-mapped BB\n",
        "  alpha = math.radians(-angle)\n",
        "  rotationMatrix = np.array([[math.cos(alpha), -math.sin(alpha)], [math.sin(alpha), math.cos(alpha)]])\n",
        "  xy = np.array([[box[0]+ox-zx],[zy-box[1]-oy]])\n",
        "  xy_ = np.matmul(rotationMatrix, xy)\n",
        "  xy_ = np.transpose(xy_)\n",
        "  xy_[0][0] = xy_[0][0] + zx\n",
        "  xy_[0][1] = zy - xy_[0][1]\n",
        "  xy_ = xy_.tolist()\n",
        "  cx = int(xy_[0][0])\n",
        "  cy = int(xy_[0][1])\n",
        "  # calculate angle for reverse-mapped BB\n",
        "  dx = cx - zx\n",
        "  dy = zy - cy\n",
        "  if dx <= 0:\n",
        "    theta = math.atan(dy/min(-0.01,dx)) - math.pi # avoid a/0\n",
        "  else:\n",
        "    theta = math.atan(dy/dx)\n",
        "  theta = math.degrees(theta)\n",
        "  box[0] = cx\n",
        "  box[1] = cy\n",
        "  box[7] = theta\n",
        "  return box"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h6tOwAw672WR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def topoints(shape,box):\n",
        "  # ****************************************************************************\n",
        "  # Get the coordinates of four vertices of BBs in fisheye image\n",
        "  # input: 1. shape: shape of fisheye image\n",
        "  #        2. box: BBs to interpret \n",
        "  # output: list of cooperates of four vertices of the BB\n",
        "  # ****************************************************************************\n",
        "  \n",
        "  \n",
        "  # set center of image as origin.\n",
        "  ox = int(shape[0]/2)\n",
        "  oy = int(shape[0]/2)\n",
        "  # get coordinate of center of BB in the new coordinate system\n",
        "  cx = box[0] - ox\n",
        "  cy = oy - box[1]\n",
        "  # calculate four vertices based on a series of tiangular calculations\n",
        "  theta = math.radians(box[7])\n",
        "  wc = box[2]*math.cos(theta)/2\n",
        "  hc = box[3]*math.cos(theta)/2\n",
        "  ws = box[2]*math.sin(theta)/2\n",
        "  hs = box[3]*math.sin(theta)/2\n",
        "  sign = [[-1,1,1,1,],[1,1,-1,1],[1,-1,-1,-1],[-1,-1,1,-1]]\n",
        "  # output\n",
        "  pts = []\n",
        "  for i in sign:\n",
        "    pts.append((int(cx+i[0]*ws+i[1]*hc)+ox,oy-int(cy+i[2]*wc+i[3]*hs)))\n",
        "  return(pts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a1mn-nW678mc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def drawBB(image,boxes,color):\n",
        "  # ****************************************************************************\n",
        "  # function to draw BBs \n",
        "  # input: 1. image: image to draw BBs on\n",
        "  #        2. boxes: Bounding boxes to draw\n",
        "  #        3. color: color for BB\n",
        "  # ****************************************************************************\n",
        "  \n",
        "  \n",
        "  for box in boxes:\n",
        "    pts = topoints(image.shape,box) # get the vertices of BB\n",
        "    for i in range(0,5):\n",
        "      cv.line(image,pts[i%4],pts[(i-1)%4],color,3) # link vertices in order"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rjfr0-Ynbokm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def randomize(image,num):\n",
        "  # ****************************************************************************\n",
        "  # function to add randomisty to small image candidate for verification\n",
        "  # input: 1. image: small image\n",
        "  #        2. num: number of small image, used to select random seed for gaussian noise\n",
        "  # output: horizontally flipped small image with noise\n",
        "  \n",
        "  # *********************NOT USED IN THESIS*************************************\n",
        "  # ****************************************************************************\n",
        "  \n",
        "  \n",
        "  image = cv.flip(image, 1) # flip horizontally\n",
        "  np.random.seed(num)  # select a random seed\n",
        "  noise = np.random.normal(20,10,image.shape) # generate 2D gaussian noise\n",
        "  noise[noise<0]=0 # truncate the noise into range of o to 255\n",
        "  noise[noise>255] = 255\n",
        "  for i in range(0,3):\n",
        "    image[:,:,i] = image[:,:,i] #+ noise[:,:,i]    #add the noise to image\n",
        "    cv.imwrite(savepath+str(num)+\"_\"+str(i)+\".jpg\",image)\n",
        "  return image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EV-rn1ULBLbF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def NMS(boxes, shape ,th):\n",
        "  # ****************************************************************************\n",
        "  # function to merge reverse-mapped boxes using NMS-based method\n",
        "  # detail can be found in 3.6.1 of Shengye's thesis\n",
        "  # pseudo code avaibliable in Algorithm 1 of my thesis\n",
        "  # input: 1. boxes: all BBs after reverse mapping\n",
        "  #        2. shape: shape of fisheye image\n",
        "  #        3. th: threshold for IOU. if IOU > th, two BBs will be merged.\n",
        "  # output: a group of BBs of which any pair's IOU < th\n",
        "  # ****************************************************************************\n",
        "  \n",
        "  \n",
        "  xsize = shape[0]\n",
        "  ysize = shape[1]\n",
        "  confidences = [] #list to store confidence score \n",
        "  result = [] # list of output, initialized here\n",
        "  # extract the confidence score from input BBs, and sort it in descending order.\n",
        "  for box in boxes:\n",
        "    confidences.append(box[6])\n",
        "  idxs = sorted(range(len(confidences)), key=lambda k: confidences[k],reverse=True)\n",
        "  # NMS \n",
        "  for ii in range(len(idxs)):\n",
        "    # if output list is empty, append the BB with highest conf. directly\n",
        "    if ii == 0:\n",
        "      result.append(boxes[idxs[ii]]) \n",
        "    else:\n",
        "      \n",
        "      i = idxs[ii]\n",
        "      # get the area of rotated rectangle by count pixels\n",
        "      # In the later version of opencv, NMS for rotated rectangles is available,\n",
        "      # Strongly suggest to change to that function provided by opencv which calculate IOU anatically.\n",
        "      refi = np.zeros((xsize,ysize))\n",
        "      pts = topoints((xsize,ysize),boxes[i])\n",
        "      contours = np.array([pts[0],pts[1],pts[2],pts[3]])\n",
        "      cv.fillPoly(refi, pts =[contours], color=(1,1,1)) \n",
        "      si = boxes[i][2]*boxes[i][3]\n",
        "      addable = 1 # flag: if it is able to add the BB into output list\n",
        "      for j in range(len(result)):\n",
        "        refj = np.zeros((xsize,ysize))\n",
        "        pts = topoints((xsize,ysize),result[j])\n",
        "        contours = np.array([pts[0],pts[1],pts[2],pts[3]])\n",
        "        cv.fillPoly(refj, pts =[contours], color=(1,1,1))\n",
        "        sj = si = result[j][2]*result[j][3]\n",
        "        ref = refj + refi\n",
        "        so = len(np.argwhere(ref == 2))\n",
        "        iou = so / (sj + si - so) # calculate IOU\n",
        "        # if IOU of this BBs and any of outputs(whose confidence socre is higher) > TH, \n",
        "        # suppress the BB.\n",
        "        if iou > th: \n",
        "          addable = 0\n",
        "          break\n",
        "      if addable == 1:\n",
        "        # otherwise append BB to the final output.\n",
        "        result.append(boxes[i])\n",
        "  return result\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eQO2C155Sjt_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def KMEANS(im, bbs):\n",
        "  # ****************************************************************************\n",
        "  # function to merge all BBs after reverse mapping using clustering-based method\n",
        "  # detail can be found in 3.6.2 of shengye's thesis\n",
        "  # input: 1. im: fisheye images\n",
        "  #        2. bbs: BBs after reverse mapping\n",
        "  # output: a list of BBs after merging. \n",
        "  # ****************************************************************************\n",
        "  \n",
        "  # compose feature vectors\n",
        "  bbs = np.asarray(bbs)\n",
        "  features = np.zeros((bbs.shape[0],12)) # compose a 12-dimensional feature vector\n",
        "  features[:,0] = bbs[:,0]/2048 # normalize x\n",
        "  features[:,1] = bbs[:,1]/2048 # normalize y\n",
        "  T = bbs[:,7]\n",
        "  X = bbs[:,0]\n",
        "  Y = bbs[:,1]\n",
        "  W = bbs[:,2]\n",
        "  H = bbs[:,3]\n",
        "  # start compose the grayscale histogram for feature vector\n",
        "  for i, delta in enumerate(T):\n",
        "    # first rotate the BB to upright position\n",
        "    M = cv.getRotationMatrix2D((cf.shape[0]/2,cf.shape[1]/2),90-delta,1)\n",
        "    image = cv.warpAffine(cf,M,(cf.shape[0],cf.shape[1]))\n",
        "    dx = X[i] - 1024\n",
        "    dy = 1024 - Y[i]\n",
        "    alpha = math.radians(90-delta)\n",
        "    rotationMatrix = np.array([[math.cos(alpha), -math.sin(alpha)], [math.sin(alpha), math.cos(alpha)]])\n",
        "    xy = np.array([[dx],[dy]])\n",
        "    xy_ = np.matmul(rotationMatrix, xy)\n",
        "    xy_ = np.transpose(xy_)\n",
        "    xy_ = xy_.tolist()\n",
        "    cx = int(xy_[0][0]) + 1024\n",
        "    cy = 1024 - int(xy_[0][1])\n",
        "    margin = 0 # get area exactly same as BB\n",
        "    # calculate the four vertices of rectangular area to extract grayscale histogram\n",
        "    top = max(cy - margin - int(H[i] / 2),0)\n",
        "    left = max(cx - margin - int(W[i] / 2),0)\n",
        "    right = min(cx + margin + int(W[i] / 2),2048)\n",
        "    bottom = min(cy + margin + int(H[i] / 2),2048)  \n",
        "    roi = image[top:bottom,left:right,:] # extract area inside of BB from fisheye image\n",
        "    roi = cv.cvtColor(roi, cv.COLOR_BGR2GRAY) # convert to grayscale\n",
        "    roi.reshape(1,roi.shape[0]*roi.shape[1]) # reshape to 1*n vector\n",
        "    hist = np.histogram(roi,bins=10,range=(0,260),density=False) # 10-bin historgram\n",
        "    features[i,2:12] = 0.8 * hist[0] / (roi.shape[0]*roi.shape[1])\n",
        "  inertia = np.zeros((features.shape[0]))\n",
        "  costf = np.zeros((features.shape[0]))\n",
        "  y = range(1,features.shape[0]+1)\n",
        "  for i in range(1, features.shape[0]+1): \n",
        "    kmeans = KMeans(n_clusters = i, random_state=0) # do kmeans with fixed random seed\n",
        "    kmeans.fit(features) # input features\n",
        "    inertia[i-1] = kmeans.inertia_  # cost function without regularization\n",
        "    costf[i-1] = kmeans.inertia_ + 0.0025*i**2 # cost function with regularization\n",
        "# # plot and save the cost function if needed\n",
        "#   plt.plot(inertia)\n",
        "#   plt.savefig(savepath + \"Kmeans_\" + str(numberofframe) + \".jpg\")\n",
        "#   plt.clf()\n",
        "#   plt.plot(costf)\n",
        "#   plt.savefig(savepath + \"Cost_\" + str(numberofframe) + \".jpg\")\n",
        "#   plt.clf()\n",
        "#   numofcluster = elbow(costf)\n",
        "#   print(costf)\n",
        "#   print(inertia)\n",
        "  numofcluster = np.argmin(costf) + 1 # find the K with minimum cost\n",
        "  kmeans = KMeans(n_clusters = numofcluster, random_state=0) # do Kmeans again to cluster\n",
        "  kmeans.fit(features)\n",
        "  result = []\n",
        "  # generate a representeive BB for each cluster(person)\n",
        "  for i in range(0,numofcluster):\n",
        "    cx = int(np.mean(features[kmeans.labels_ == i,0])*2048)\n",
        "    cy = int(np.mean(features[kmeans.labels_ == i,1])*2048)\n",
        "    width = int(np.mean(bbs[kmeans.labels_ == i,2]))\n",
        "    height = int(np.mean(bbs[kmeans.labels_ == i,3]))\n",
        "    dx = cx - 1024\n",
        "    dy = 1024 - cy\n",
        "    if dx <= 0:\n",
        "      theta = math.atan(dy/min(-0.01,dx)) - math.pi\n",
        "    else:\n",
        "      theta = math.atan(dy/dx)\n",
        "    result.append([cx,cy,width,height,0,0,0,math.degrees(theta)])\n",
        "  return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zfu_IRbp8xi_",
        "colab_type": "code",
        "outputId": "348b94d2-6b69-49e2-dd89-c00399b5d116",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1037
        }
      },
      "cell_type": "code",
      "source": [
        "# list to count time\n",
        "time_detection = []\n",
        "time_counting = []\n",
        "time_verification = []\n",
        "\n",
        "# main steps begin here\n",
        "for numberofframe in range(1,1772,30): \n",
        "  cf = cv.imread(readpath + str(numberofframe) + \".jpg\")\n",
        "  begin = time.time() # time counting begins\n",
        "  loaded_ims = [] #images feed into YOLO\n",
        "  psize = 0 # find the size for reshae \n",
        "  \n",
        "  # get roi---------------------------------------------------------------------\n",
        "  for angle in range(0, 360, 15):\n",
        "    # rotate image by 15 degree, and extract a window of 800*1300 from its top-center \n",
        "    M = cv.getRotationMatrix2D((cf.shape[0]/2,cf.shape[1]/2),angle,1)\n",
        "    rotation = cv.warpAffine(cf,M,(cf.shape[0],cf.shape[1]))\n",
        "    roi = rotation[0:1300,624:1424,:]\n",
        "    loaded_ims.append(roi)\n",
        "    psize = max(roi.shape[0],roi.shape[1],psize)\n",
        "    \n",
        "  # prepart batch---------------------------------------------------------------\n",
        "  batch_size = 2 # divide 24 images into bathes, and feed into YOLO\n",
        "  psize = int(np.ceil(psize/32)*32) # image feed into YOLO must have a shape of n*32\n",
        "  model.net_info[\"height\"] = int(psize) # set input size for darknet \n",
        "  model.cuda() \n",
        "  im_batches = list(map(padding, loaded_ims, [psize for x in range(len(loaded_ims))])) # zero-padding images\n",
        "  im_dim_list = [(x.shape[1], x.shape[0]) for x in loaded_ims]\n",
        "  im_dim_list = torch.FloatTensor(im_dim_list).repeat(1,2)\n",
        "  leftover = 0\n",
        "  if (len(im_dim_list) % batch_size):\n",
        "    leftover = 1\n",
        "  if batch_size != 1:\n",
        "    num_batches = len(loaded_ims) // batch_size + leftover            \n",
        "    im_batches = [torch.cat((im_batches[i*batch_size : min((i +  1)*batch_size, \n",
        "                                                           len(im_batches))]))  for i in range(num_batches)]  \n",
        "  im_dim_list = im_dim_list.cuda()\n",
        "  \n",
        "  # detection-------------------------------------------------------------------\n",
        "  persons = [] # list to store people detection result\n",
        "  for i, batch in enumerate(im_batches):\n",
        "    batch = batch.cuda()\n",
        "    with torch.no_grad():\n",
        "      prediction = model(Variable(batch), CUDA)\n",
        "    # parameters for write_result(prediction, objectness, number of classes, TH of IOU for NMS)  \n",
        "    prediction = write_results(prediction, 0.3, 80, nms_conf = 0.4)\n",
        "    if type(prediction) != int:\n",
        "      for pred in prediction:\n",
        "        detection = pred.cpu().numpy()\n",
        "        ind = int(pred[0])\n",
        "        factor = 1312 / psize # zoom in/zoom out factor, if image feed into yolo is down-sampled, this is necessary\n",
        "        cx = int(factor * (detection[1] + detection[3])/2)\n",
        "        cy = int(factor * (detection[2] + detection[4])/2)\n",
        "        width = int(factor * (detection[3] - detection[1]))\n",
        "        height = int(factor * (detection[4] - detection[2]))\n",
        "        objectness = detection[5]\n",
        "        confidence = detection[6]\n",
        "        classId = int(detection[7])\n",
        "        top = cy - height / 2\n",
        "        left = cx - width / 2\n",
        "        right = cx + width / 2\n",
        "        bottom = cy + height / 2\n",
        "        box = [cx, cy, width, height, objectness, classId, confidence, (i*batch_size+ind)*15]\n",
        "        #      0    1    2       3         4         5         6               7\n",
        "        if classId == 0:  # only people detection is accepted here\n",
        "          if left > 50 and right < 750 and bottom < 1250: # spatial outlier rejection with delta = 50\n",
        "          persons.append(box)\n",
        "#             print(box)\n",
        "  \n",
        "  # Reverse Map-----------------------------------------------------------------\n",
        "  im = cf.copy()\n",
        "  BBs = list(map(reverseMap, persons, [(2048,2048) for x in persons])) # reverse map\n",
        "  drawBB(im, BBs, (255,0, 0)) # draw result of reverse map in blue\n",
        "  \n",
        "  stop = time.time()\n",
        "  time_detection.append(stop-begin)\n",
        "#   print(stop-begin)\n",
        "  \n",
        "  # People counting ------------------------------------------------------------\n",
        "  BBs = NMS(BBs, (2048, 2048), 0.4)   # choose between NMS and KMEANS\n",
        "#   BBs = KMEANS(cf, BBs)\n",
        "  drawBB(im, BBs, (0, 255,0))\n",
        "#   drawBB(im, BBs, (0,0, 255))\n",
        "  stop1 = time.time()\n",
        "#   print(stop1-stop)\n",
        "  time_counting.append(stop1-stop)\n",
        "  \n",
        "\n",
        "# varification------------------------------------------------------------------\n",
        "  verified_result = [] # list to store verified result\n",
        "  for numberofbox, box in enumerate(BBs):\n",
        "    # prepare batch\n",
        "    positive = 0    # number of \"Yes\" vote\n",
        "    psize = 0       # size for zero-padding\n",
        "    loaded_ims = [] \n",
        "    candidates = []\n",
        "    # rotate BB to up-right position\n",
        "    M = cv.getRotationMatrix2D((cf.shape[0]/2,cf.shape[1]/2),90-box[7],1)\n",
        "    image = cv.warpAffine(cf,M,(cf.shape[0],cf.shape[1]))\n",
        "    dx = box[0] - 1024\n",
        "    dy = 1024 - box[1]\n",
        "    alpha = math.radians(90-box[7])\n",
        "    rotationMatrix = np.array([[math.cos(alpha), -math.sin(alpha)], [math.sin(alpha), math.cos(alpha)]])\n",
        "    xy = np.array([[dx],[dy]])\n",
        "    xy_ = np.matmul(rotationMatrix, xy)\n",
        "    xy_ = np.transpose(xy_)\n",
        "    xy_ = xy_.tolist()\n",
        "    cx = int(xy_[0][0]) + 1024\n",
        "    cy = 1024 - int(xy_[0][1])\n",
        "    pts = topoints((2048,2048),[cx,cy,box[2],box[3],0,0,0,90-box[7]])   \n",
        "    # extract margin slightly larger than BB\n",
        "    margin = 30\n",
        "    top = max(cy - margin - int(box[3] / 2),0)\n",
        "    left = max(cx - margin - int(box[2] / 2),0)\n",
        "    right = min(cx + margin + int(box[2] / 2),2048)\n",
        "    bottom = min(cy + margin + int(box[3] / 2),2048)    \n",
        "    roi_0 = image[top:bottom,left:right,:] # extract the upright image \n",
        "    roi_n10 = ndimage.rotate(roi_0, -15) # further rotate -15 degrees\n",
        "    roi_p10 = ndimage.rotate(roi_0, 15) # future rotate 15 degrees\n",
        "    \n",
        "    loaded_ims.append(randomize(roi_n10,0))\n",
        "    loaded_ims.append(randomize(roi_0,1))\n",
        "    loaded_ims.append(randomize(roi_p10,2))\n",
        "                                 \n",
        "    for mmm, roi in enumerate(loaded_ims):\n",
        "      psize = max(roi.shape[0],roi.shape[1],psize) \n",
        "#       cv.imwrite(savepath + \"verification_\"+str(numberofbox)+\"_\"+str(mmm)+\".jpg\", roi)\n",
        "    batch_size = 3\n",
        "    psize = int(np.ceil(psize/32)*32) # repeat steps in detection part\n",
        "    model.net_info[\"height\"] = int(psize)\n",
        "    model.cuda()\n",
        "    im_batches = list(map(padding, loaded_ims, [psize for x in range(len(loaded_ims))]))\n",
        "    im_dim_list = [(x.shape[1], x.shape[0]) for x in loaded_ims]\n",
        "    im_dim_list = torch.FloatTensor(im_dim_list).repeat(1,2)\n",
        "    leftover = 0\n",
        "    if (len(im_dim_list) % batch_size):\n",
        "      leftover = 1\n",
        "    if batch_size != 1:\n",
        "      num_batches = len(loaded_ims) // batch_size + leftover            \n",
        "      im_batches = [torch.cat((im_batches[i*batch_size : min((i + 1)*batch_size, \n",
        "                                                             len(im_batches))]))  for i in range(num_batches)]  \n",
        "    im_dim_list = im_dim_list.cuda()\n",
        "    \n",
        "    # detection\n",
        "    for i, batch in enumerate(im_batches):\n",
        "      batch = batch.cuda()\n",
        "      with torch.no_grad():\n",
        "        prediction = model(Variable(batch), CUDA)\n",
        "      prediction = write_results(prediction, 0.3, 80, nms_conf = 0) # set TH of IOU for NMS as 0\n",
        "      if type(prediction) != int:\n",
        "        for pred in prediction:\n",
        "          detection = pred.cpu().numpy()\n",
        "          ind = int(pred[0])\n",
        "          factor = 1\n",
        "          cx = int(factor * (detection[1] + detection[3])/2)\n",
        "          cy = int(factor * (detection[2] + detection[4])/2)\n",
        "          width = int(factor * (detection[3] - detection[1]))\n",
        "          height = int(factor * (detection[4] - detection[2]))\n",
        "          objectness = detection[5]\n",
        "          confidence = detection[6]\n",
        "          classId = int(detection[7])\n",
        "          veri = [cx, cy, width, height, objectness, classId, confidence, (i*batch_size+ind)*15-15]\n",
        "          #      0    1    2       3         4         5         6               7\n",
        "          if classId == 0 : # if person is detected again \n",
        "            candidates.append(veri) \n",
        "#             print(\"numberofbox: \", str(numberofbox))\n",
        "#             print(veri)\n",
        "    # vote     \n",
        "    if len(candidates) >= 2: # majority vote\n",
        "      verified_result.append(box)\n",
        "      \n",
        "  #output number and location\n",
        "  stop2 = time.time()\n",
        "  print(numberofframe,end=\": \")\n",
        "  print(stop-begin)\n",
        "  drawBB(im, verified_result, (0,0,255)) # draw verified detections in red\n",
        "  time_verification.append(stop2-stop1)\n",
        "  cv.imwrite(savepath + \"result_\" + str(numberofframe) + \".jpg\", im)\n",
        "  torch.cuda.empty_cache()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1: 11.385071992874146\n",
            "31: 6.701092004776001\n",
            "61: 6.644094705581665\n",
            "91: 6.701834201812744\n",
            "121: 6.81547474861145\n",
            "151: 6.629377365112305\n",
            "181: 6.709620952606201\n",
            "211: 6.81677508354187\n",
            "241: 6.750072002410889\n",
            "271: 6.65874981880188\n",
            "301: 6.6915953159332275\n",
            "331: 6.643157958984375\n",
            "361: 6.6420509815216064\n",
            "391: 6.772690773010254\n",
            "421: 6.619839191436768\n",
            "451: 6.696686506271362\n",
            "481: 6.721127510070801\n",
            "511: 6.67776346206665\n",
            "541: 6.685604572296143\n",
            "571: 6.64749550819397\n",
            "601: 6.675662040710449\n",
            "631: 6.616559982299805\n",
            "661: 6.667273998260498\n",
            "691: 6.8541998863220215\n",
            "721: 6.648043155670166\n",
            "751: 6.655616283416748\n",
            "781: 6.8182759284973145\n",
            "811: 6.672439098358154\n",
            "841: 6.680182456970215\n",
            "871: 6.677645444869995\n",
            "901: 6.662112474441528\n",
            "931: 6.645489931106567\n",
            "961: 6.705803394317627\n",
            "991: 6.68884015083313\n",
            "1021: 6.8799214363098145\n",
            "1051: 6.789689779281616\n",
            "1081: 6.6996870040893555\n",
            "1111: 6.677989959716797\n",
            "1141: 6.694930553436279\n",
            "1171: 6.707648754119873\n",
            "1201: 6.803877592086792\n",
            "1231: 6.644177198410034\n",
            "1261: 6.854305982589722\n",
            "1291: 6.715635776519775\n",
            "1321: 6.703371524810791\n",
            "1351: 6.630671501159668\n",
            "1381: 6.626855373382568\n",
            "1411: 6.646297454833984\n",
            "1441: 6.6438963413238525\n",
            "1471: 6.692012071609497\n",
            "1501: 6.6812403202056885\n",
            "1531: 6.877861261367798\n",
            "1561: 6.680922269821167\n",
            "1591: 6.659036159515381\n",
            "1621: 6.7783427238464355\n",
            "1651: 6.669725656509399\n",
            "1681: 6.737361431121826\n",
            "1711: 6.866792440414429\n",
            "1741: 6.619033098220825\n",
            "1771: 6.621954441070557\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2BNE3Xa76wEQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2u-QuGsbol_v",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# output time counting of each steps\n",
        "with open(savepath+\"time_detection.csv\", mode='w') as box_file:\n",
        "  box_writer = csv.writer(box_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "  for i in time_detection:\n",
        "    box_writer.writerow([i])\n",
        "with open(savepath+\"time_counting.csv\", mode='w') as box_file:\n",
        "  box_writer = csv.writer(box_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "  for i in time_counting:\n",
        "    box_writer.writerow([i])  \n",
        "with open(savepath+\"time_verification.csv\", mode='w') as box_file:\n",
        "  box_writer = csv.writer(box_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "  for i in time_verification:\n",
        "    box_writer.writerow([i])    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rum0Qs0bpzjP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x7FzOY6Lp2Jz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cECl2v6rr2Xa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vUT9IRl2p5vK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}